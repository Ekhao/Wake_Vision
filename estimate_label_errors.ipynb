{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python notebook is used to cycle through parts of the visual wake words and wake vision dataset to estimate the amount of label errors in each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a few variables that control how this notebook works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_check = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wake_vision_loader\n",
    "import vww_loader\n",
    "import qsl\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import experiment_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the default configuration to get higher quality images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = experiment_config.get_cfg(\"estimate_label_errors_cfg\")\n",
    "cfg.INPUT_SHAPE= (448, 448, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,vww_test = vww_loader.get_vww(cfg)\n",
    "_,_,wv_test = wake_vision_loader.get_wake_vision(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbatch the datasets to later fetch one image at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vww_test = vww_test.unbatch()\n",
    "wv_test = wv_test.unbatch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set up a qsl medialabeller to label the vww set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vww_params = dict(\n",
    "    config={\n",
    "        \"image\": [\n",
    "            {\n",
    "                \"name\": \"Correct Label\",\n",
    "                \"options\": [{\"name\": \"Person\"},{\"name\": \"No Person\"}],\n",
    "                \"required\": True,\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    items=[\n",
    "        {\n",
    "            \"target\": cv2.cvtColor(tf.image.convert_image_dtype(sample[0], tf.uint8).numpy(), cv2.COLOR_RGB2BGR),\n",
    "            \"metadata\": {\"orig_label\": sample[1].numpy()},\n",
    "            \"image_num\": i,\n",
    "        } for i, sample in enumerate(vww_test.take(samples_to_check))\n",
    "    ],\n",
    "    maxCanvasSize=224,\n",
    ")\n",
    "\n",
    "vww_labeller = qsl.MediaLabeler(**vww_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the labeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vww_labeller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the amount of errors from the labelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vww_output = [\n",
    "    {\n",
    "        \"correct_label\": item[\"labels\"][\"image\"][\"Correct Label\"],\n",
    "        \"original_label\": item[\"metadata\"][\"orig_label\"],\n",
    "    } for item in vww_labeller.items\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry, sample in enumerate(vww_output):\n",
    "    if sample[\"correct_label\"] == [\"Person\"]:\n",
    "        vww_output[entry][\"correct_label\"] = 1\n",
    "    elif sample[\"correct_label\"] == [\"No Person\"]:\n",
    "        vww_output[entry][\"correct_label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vww_errors = 0\n",
    "for sample in vww_output:\n",
    "    if sample[\"correct_label\"] != sample[\"original_label\"]:\n",
    "        vww_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"VWW Errors: {vww_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next do the same thing for the wake vision dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_params = dict(\n",
    "    config={\n",
    "        \"image\": [\n",
    "            {\n",
    "                \"name\": \"Correct Label\",\n",
    "                \"options\": [{\"name\": \"Person\"},{\"name\": \"No Person\"}],\n",
    "                \"required\": True,\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Depiction\",\n",
    "                \"options\": [{\"name\": \"Depiction\", \"shortcut\": \"æ\"}, {\"name\": \"No Depiction\", \"shortcut\": \"ø\"}],\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    items=[\n",
    "        {\n",
    "            \"target\": cv2.cvtColor(tf.image.convert_image_dtype(sample[0], tf.uint8).numpy(), cv2.COLOR_RGB2BGR),\n",
    "            \"metadata\": {\"orig_label\": sample[1].numpy()},\n",
    "            \"image_num\": i,\n",
    "        } for i, sample in enumerate(wv_test.take(samples_to_check))\n",
    "    ],\n",
    "    maxCanvasSize=224,\n",
    ")\n",
    "\n",
    "wv_labeller = qsl.MediaLabeler(**wv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(wv_labeller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_output = [\n",
    "    {\n",
    "        \"correct_label\": item[\"labels\"][\"image\"][\"Correct Label\"],\n",
    "        \"depiction\": item[\"labels\"][\"image\"][\"Depiction\"],\n",
    "        \"original_label\": item[\"metadata\"][\"orig_label\"],\n",
    "    } for item in wv_labeller.items\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry, sample in enumerate(wv_output):\n",
    "    if sample[\"correct_label\"] == [\"Person\"]:\n",
    "        wv_output[entry][\"correct_label\"] = 1\n",
    "    elif sample[\"correct_label\"] == [\"No Person\"]:\n",
    "        wv_output[entry][\"correct_label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_no_depiction_errors = 0\n",
    "for sample in wv_output:\n",
    "    if sample[\"correct_label\"] != sample[\"original_label\"] and sample[\"depiction\"] == [\"No Depiction\"]:\n",
    "        wv_no_depiction_errors += 1\n",
    "wv_depiction_errors = 0\n",
    "for sample in wv_output:\n",
    "    if sample[\"correct_label\"] != sample[\"original_label\"] and sample[\"depiction\"] == [\"Depiction\"]:\n",
    "        wv_depiction_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Wake Vision Non-Depiction Errors: {wv_no_depiction_errors}\")\n",
    "print(f\"Wake Vision Depiction Errors: {wv_depiction_errors}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
