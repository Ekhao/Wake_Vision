{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this noteboox we use the open source cleanlab tool to identify issues with the wake vision validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only once to be able to import modules from the project root directory\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import cleanlab\n",
    "import datasets\n",
    "import yaml\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import wake_vision_loader\n",
    "from ml_collections import config_dict\n",
    "from experiment_config import default_cfg as cfg\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the dataset that we are interested in cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_path_list = glob.glob(f\"tmp/wv_image_folder/{SPLIT}/person/*\")\n",
    "no_person_path_list = glob.glob(f\"tmp/wv_image_folder/{SPLIT}/no_person/*\")\n",
    "\n",
    "person_dataset = datasets.Dataset.from_dict(\n",
    "    {\n",
    "        \"image\": person_path_list,\n",
    "        \"filename\": list(map(os.path.basename, person_path_list)),\n",
    "        \"label\": [1] * len(person_path_list),\n",
    "    }\n",
    ").cast_column(\"image\", datasets.Image())\n",
    "\n",
    "no_person_dataset = datasets.Dataset.from_dict(\n",
    "    {\n",
    "        \"image\": no_person_path_list,\n",
    "        \"filename\": list(map(os.path.basename, no_person_path_list)),\n",
    "        \"label\": [0] * len(no_person_path_list),\n",
    "    }\n",
    ").cast_column(\"image\", datasets.Image())\n",
    "\n",
    "ds = datasets.concatenate_datasets([person_dataset, no_person_dataset])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize the cleanlab Datalab using the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = cleanlab.Datalab(data=ds,label_name=\"label\", image_key=\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to use a model to get predicted probabilities for our dataset. We can make use of one of our models previously trained on the training set for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get a model that we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_yaml = \"gs://wake-vision-storage/saved_models/bbox_trained2024_01_25-07_17_34_PM/config.yaml\"\n",
    "\n",
    "with tf.io.gfile.GFile(model_yaml, 'r') as fp:\n",
    "    cfg = yaml.unsafe_load(fp)\n",
    "    cfg = config_dict.ConfigDict(cfg)\n",
    "\n",
    "model_path = cfg.SAVE_FILE\n",
    "model = keras.saving.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this model to get predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_ds = ds.to_tf_dataset(columns=[\"image\", \"label\"])\n",
    "def rename_label(x):\n",
    "    x[\"person\"] = x[\"label\"]\n",
    "    return x\n",
    "tf_ds = tf_ds.map(rename_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "tf_ds = wake_vision_loader.preprocessing(tf_ds, batch_size = 128,cfg=cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probabilities = model.predict(tf_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the predicted probabilites, we can improve the issue finding by also generating feature embeddings. We can simply get these embeddings from the model that we used to get the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = keras.Model(inputs=model.inputs, outputs=model.get_layer(\"global_average_pooling2d\").output)\n",
    "embeddings = embedding_model.predict(tf_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the predicted probabilities and the embeddings to find issues in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.find_issues(pred_probs=pred_probabilities, features = embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see a report of the issues found in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first plot some of hte label issues found in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_issues = lab.get_issues(\"label\")\n",
    "label_issues_df = label_issues.query(\"is_label_issue\").sort_values(\"label_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_issue_examples(label_issues_df, num_examples=15):\n",
    "    ncols = 5\n",
    "    nrows = int(math.ceil(num_examples / ncols))\n",
    "\n",
    "    _, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(1.5 * ncols, 1.5 * nrows))\n",
    "    axes_list = axes.flatten()\n",
    "    label_issue_indices = label_issues_df.index.values\n",
    "\n",
    "    for i, ax in enumerate(axes_list):\n",
    "        if i >= num_examples:\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        idx = int(label_issue_indices[i])\n",
    "        row = label_issues.loc[idx]\n",
    "        ax.set_title(\n",
    "            f\"id: {idx}\\n GL: {row.given_label}\\n SL: {row.predicted_label}\",\n",
    "            fontdict={\"fontsize\": 8},\n",
    "        )\n",
    "        ax.imshow(ds[idx][\"image\"], cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_issue_examples(label_issues_df, num_examples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let us take a look at some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_issues_df = lab.get_issues(\"outlier\")\n",
    "outlier_issues_df = outlier_issues_df.query(\"is_outlier_issue\").sort_values(\"outlier_score\")\n",
    "# Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "def plot_outlier_issues_examples(outlier_issues_df, num_examples):\n",
    "    ncols = 4\n",
    "    nrows = num_examples\n",
    "    N_comparison_images = ncols - 1\n",
    "\n",
    "    def sample_from_class(label, number_of_samples, index):\n",
    "        index = int(index)\n",
    "\n",
    "        non_outlier_indices = (\n",
    "            label_issues.join(outlier_issues_df)\n",
    "            .query(\"given_label == @label and is_outlier_issue.isnull()\")\n",
    "            .index\n",
    "        )\n",
    "        non_outlier_indices_excluding_current = non_outlier_indices[non_outlier_indices != index]\n",
    "\n",
    "        sampled_indices = np.random.choice(\n",
    "            non_outlier_indices_excluding_current, number_of_samples, replace=False\n",
    "        )\n",
    "\n",
    "        label_scores_of_sampled = label_issues.loc[sampled_indices][\"label_score\"]\n",
    "\n",
    "        top_score_indices = np.argsort(label_scores_of_sampled.values)[::-1][:N_comparison_images]\n",
    "\n",
    "        top_label_indices = sampled_indices[top_score_indices]\n",
    "\n",
    "        sampled_images = [ds[int(i)][\"image\"] for i in top_label_indices]\n",
    "\n",
    "        return sampled_images\n",
    "\n",
    "    def get_image_given_label_and_samples(idx):\n",
    "        image_from_dataset = ds[idx][\"image\"]\n",
    "        corresponding_label = label_issues.loc[idx][\"given_label\"]\n",
    "        comparison_images = sample_from_class(corresponding_label, 30, idx)[:N_comparison_images]\n",
    "\n",
    "        return image_from_dataset, corresponding_label, comparison_images\n",
    "\n",
    "    count = 0\n",
    "    images_to_plot = []\n",
    "    labels = []\n",
    "    idlist = []\n",
    "    for idx, row in outlier_issues_df.iterrows():\n",
    "        idx = row.name\n",
    "        image, label, comparison_images = get_image_given_label_and_samples(idx)\n",
    "        labels.append(label)\n",
    "        idlist.append(idx)\n",
    "        images_to_plot.append(image)\n",
    "        images_to_plot.extend(comparison_images)\n",
    "        count += 1\n",
    "        if count >= nrows:\n",
    "            break\n",
    "\n",
    "    ncols = 1 + N_comparison_images\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(1.5 * ncols, 1.5 * nrows))\n",
    "    axes_list = axes.flatten()\n",
    "    for i, ax in enumerate(axes_list):\n",
    "        if i % ncols == 0:\n",
    "            ax.set_title(f\"id: {idlist[i // ncols]}\\n GL: {labels[i // ncols]}\", fontdict={\"fontsize\": 8})\n",
    "        ax.imshow(images_to_plot[i], cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "    plt.show()\n",
    "plot_outlier_issues_examples(outlier_issues_df, num_examples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see some near duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicate_issues_df = lab.get_issues(\"near_duplicate\")\n",
    "near_duplicate_issues_df = near_duplicate_issues_df.query(\"is_near_duplicate_issue\").sort_values(\n",
    "    \"near_duplicate_score\"\n",
    ")\n",
    "# Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "def plot_near_duplicate_issue_examples(near_duplicate_issues_df, num_examples=3):\n",
    "    nrows = num_examples\n",
    "    seen_id_pairs = set()\n",
    "\n",
    "    def get_image_and_given_label_and_predicted_label(idx):\n",
    "        image = ds[idx][\"image\"]\n",
    "        label = label_issues.loc[idx][\"given_label\"]\n",
    "        predicted_label = label_issues.loc[idx][\"predicted_label\"]\n",
    "        return image, label, predicted_label\n",
    "\n",
    "    count = 0\n",
    "    for idx, row in near_duplicate_issues_df.iterrows():\n",
    "        image, label, predicted_label = get_image_and_given_label_and_predicted_label(idx)\n",
    "        duplicate_images = row.near_duplicate_sets\n",
    "        nd_set = set([int(i) for i in duplicate_images])\n",
    "        nd_set.add(int(idx))\n",
    "\n",
    "        if nd_set & seen_id_pairs:\n",
    "            continue\n",
    "\n",
    "        _, axes = plt.subplots(1, len(nd_set), figsize=(len(nd_set), 3))\n",
    "        for i, ax in zip(list(nd_set), axes):\n",
    "            label = label_issues.loc[i][\"given_label\"]\n",
    "            ax.set_title(f\"id: {i}\\n GL: {label}\", fontdict={\"fontsize\": 8})\n",
    "            ax.imshow(ds[i][\"image\"], cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "        seen_id_pairs.update(nd_set)\n",
    "        count += 1\n",
    "        if count >= nrows:\n",
    "            break\n",
    "\n",
    "    plt.show()\n",
    "plot_near_duplicate_issue_examples(near_duplicate_issues_df, num_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurry = lab.get_issues(\"blurry\")\n",
    "blurry_issues_df = blurry.query(\"is_blurry_issue\").sort_values(\"blurry_score\")\n",
    "plot_label_issue_examples(blurry_issues_df, num_examples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save the datalab instance to use for fixing issues in the cleanlab_fix_issues notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.save(f'tmp/wv_datalab_{SPLIT}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
